{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import datetime\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = ['CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID', 'TIMESTAMP',\n",
    "           'dist_perc', 'start_lat', 'start_lon', 'stop_lat', 'stop_lon']\n",
    "\n",
    "df = pd.read_csv('train_tratado_outliers_2.csv', usecols=usecols, parse_dates=True, nrows=300000)\n",
    "\n",
    "# cabeçalho minusculo\n",
    "df.columns = df.columns.map(lambda x: x.lower())\n",
    "#conversão da data de obj para datetime\n",
    "df.timestamp = pd.to_datetime(df.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_dados(df):\n",
    "    #--- Timestamp\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    #df['cat_hour'] = pd.cut(df.timestamp.dt.hour, [-1, 8, 16, 23], labels=[0,1,2])\n",
    "    df['hour'] = df.timestamp.dt.hour\n",
    "    del df['timestamp']\n",
    "\n",
    "    #--- Call_type\n",
    "    df['call_type'] = preprocessing.LabelEncoder().fit_transform(df['call_type'])\n",
    "    enc = OneHotEncoder().fit_transform(df[['call_type']])\n",
    "    del df['call_type']\n",
    "    df['call_type_a'] = enc.toarray()[:,0]\n",
    "    df['call_type_b'] = enc.toarray()[:,1]\n",
    "    df['call_type_c'] = enc.toarray()[:,2]\n",
    "\n",
    "    #--- Fill na\n",
    "    df.fillna(-1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trata_dados(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~**Working with polyline (get first, last and penultimate)**~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def points(x):\n",
    "#    try:\n",
    "#        \n",
    "#        global cont;\n",
    "#        \n",
    "#        line = np.array(ast.literal_eval(x))\n",
    "#        \n",
    "#        if line.size>2:\n",
    "#            return line[0][1], line[0][0], line[-2][1], line[-2][0], line[-1][1], line[-1][0]\n",
    "#        \n",
    "#        return 0,0,0,0,0,0\n",
    "#    except Exception as e:\n",
    "#        #print(e)\n",
    "#        None\n",
    "#   #finally:\n",
    "#   #    if cont%10000 ==0: print(datetime.datetime.now(), cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cont=0\n",
    "#df['sta_lat'],df['sta_lon'],df['pen_lat'],df['pen_lon'],df['sto_lat'],df['sto_lon'] = zip(*df['polyline'].apply(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df['polyline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start ML process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    #dlon = lon2 - lon1 \n",
    "    #dlat = lat2 - lat1 \n",
    "    a = sin((lat2 - lat1)/2)**2 + cos(lat1) * cos(lat2) * sin((lon2 - lon1)/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs some algorithm for comparing\n",
    "\n",
    "def algs_test(X1, X2, y1, y2):\n",
    "\n",
    "    algs =[('linear', LinearRegression()),\n",
    "           ('ridge', Ridge(random_state=99)),\n",
    "           ('lasso', Lasso(random_state=99)), #lasso 142.7065081365015 561.2795889474457\n",
    "           ('lsvr', LinearSVR(random_state=99)),\n",
    "           ('KNN reg', KNeighborsRegressor()), #KNN reg 3.3861972620770264 3.5182287757352873\n",
    "           ('gboost', GradientBoostingRegressor(random_state=99)),\n",
    "           ('ada boost', AdaBoostRegressor(random_state=99)),\n",
    "           ('rnd forest', RandomForestRegressor(random_state=99)),\n",
    "           ('xgboost', XGBRegressor(random_state=99, n_jobs=-1))\n",
    "           ]\n",
    "\n",
    "    for name, alg in algs:\n",
    "        try:\n",
    "            alg.fit(X1, y1)\n",
    "            preds = alg.predict(X2)\n",
    "\n",
    "            result = y2.copy()\n",
    "            result['pred_lat'] = preds[:,0]\n",
    "            result['pred_lon'] = preds[:,1]\n",
    "            hav_dist = result.apply(lambda x: haversine(x.stop_lon, x.stop_lat, x.pred_lon, x.pred_lat) ,axis=1) \n",
    "\n",
    "            print('normal',name, hav_dist.mean(), hav_dist.std())\n",
    "        except: # se o algoritmo nao possui suporte nativo para multioutput\n",
    "            mo = MultiOutputRegressor(alg, n_jobs=-1).fit(X1, y1)\n",
    "            preds = mo.predict(X2)\n",
    "\n",
    "            result = y2.copy()\n",
    "            result['pred_lat'] = preds[:,0]\n",
    "            result['pred_lon'] = preds[:,1]\n",
    "            hav_dist = result.apply(lambda x: haversine(x.stop_lon, x.stop_lat, x.pred_lon, x.pred_lat) ,axis=1) \n",
    "\n",
    "            print('multi',name, hav_dist.mean(), hav_dist.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://colingorrie.github.io/outlier-detection.html\n",
    "\n",
    "def outliers_iqr(ys):\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    return np.where((ys > upper_bound) | (ys < lower_bound))\n",
    "\n",
    "def outliers_z_score(ys):\n",
    "    threshold = 3\n",
    "\n",
    "    mean_y = np.mean(ys)\n",
    "    print(mean_y)\n",
    "    stdev_y = np.std(ys)\n",
    "    z_scores = [(y - mean_y) / stdev_y for y in ys]\n",
    "    return np.where(np.abs(z_scores) > threshold)\n",
    "\n",
    "\n",
    "def outliers_modified_z_score(ys):\n",
    "    threshold = 3.5\n",
    "\n",
    "    median_y = np.median(ys)\n",
    "    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in ys])\n",
    "    modified_z_scores = [0.6745 * (y - median_y) / median_absolute_deviation_y\n",
    "                         for y in ys]\n",
    "    return np.where(np.abs(modified_z_scores) > threshold)\n",
    "\n",
    "#------------#\n",
    "def train_test_mimax(df, remove_outliers=''):\n",
    "    \n",
    "    y = df[['stop_lat', 'stop_lon']]\n",
    "    X = df.drop(['stop_lat', 'stop_lon'], axis=1)\n",
    "    scaler = MinMaxScaler().fit(X)\n",
    "\n",
    "    #-- split train/test #X1, X2, y1, y2\n",
    "    X1, X2, y1, y2 = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    if(remove_outliers=='iqr'):\n",
    "        idx = outliers_iqr(X1.dist_perc)[0].tolist() \n",
    "        X1 = X1[~X1.index.isin(idx)]\n",
    "        y1 = y1[~y1.index.isin(idx)]\n",
    "    \n",
    "    if(remove_outliers=='zscore'):\n",
    "        idx = outliers_z_score(X1.dist_perc)[0].tolist() \n",
    "        X1 = X1[~X1.index.isin(idx)]\n",
    "        y1 = y1[~y1.index.isin(idx)]\n",
    "    \n",
    "    if(remove_outliers=='zscore_mod'):\n",
    "        idx = outliers_modified_z_score(X1.dist_perc)[0].tolist() \n",
    "        X1 = X1[~X1.index.isin(idx)]\n",
    "        y1 = y1[~y1.index.isin(idx)]\n",
    "        \n",
    "    #-- fit antes para treinar com todos dados e transform depois para pegar dados de \n",
    "    #-- treino com/sem outliers mas treinados com todos dados pra escala ficar igual\n",
    "    X1 = scaler.transform(X1)\n",
    "    X2 = scaler.transform(X2)\n",
    "    \n",
    "    return X1, X2, y1, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal linear 3.2638564456020216 4.60906383905595\n",
      "normal ridge 4.388145964021234 6.801949589262064\n",
      "normal lasso 33.33326825121277 274.1536739161117\n",
      "multi lsvr 3.172587565614162 4.999598708420609\n",
      "normal KNN reg 3.4925721814934696 4.876261908980907\n",
      "multi gboost 2.7986075444261864 8.309698856389755\n",
      "multi ada boost 3.3230221978902423 16.09500488109424\n",
      "normal rnd forest 2.5058967783997264 4.675219338605338\n",
      "multi xgboost 2.797081070316527 4.386391102434249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x0000000463CF8AC8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\a46396\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 482, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n"
     ]
    }
   ],
   "source": [
    "algs_test(*train_test_mimax(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing outliers by distance using IQR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algs_test(*train_test_mimax(df, 'iqr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing outliers by distance using Z-Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algs_test(*train_test_mimax(df, 'zscore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing outliers by distance using Z-Score modified**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algs_test(*train_test_mimax(df, 'zscore_mod'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remover os outliers não fez grandes mudanças no modelo. Os melhores foram os ensemble. Vamos usar o Gradient boost e Random Forest como vencedores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine2(y_real, y_pred): # def haversine2(lon1, lat1, lon2, lat2):\n",
    "    print( y_real, y_pred)\n",
    "    \n",
    "    \n",
    "    print('y_real:')\n",
    "    print(type(y_real))\n",
    "\n",
    "    print('-----')\n",
    "    print('y_pred:')\n",
    "    print(type(y_pred))\n",
    "\n",
    "    y_real['pred_lat'] = y_pred[:,0]\n",
    "    y_real['pred_lon'] = y_pred[:,1]\n",
    "    \n",
    "    return y_real.apply(lambda x: haversine(x.stop_lon, x.stop_lat, x.pred_lon, x.pred_lat) ,axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = make_scorer(haversine2, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(haversine2, greater_is_better=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_grid = {'max_depth':[10, 40],\n",
    "              'min_sample_leaf':[50, 150],\n",
    "              'max_features':[None, 8]}\n",
    "\n",
    "gs = GridSearchCV( \\\n",
    "        RandomForestRegressor(n_estimators=100, random_state=99, n_jobs=-1),  \\\n",
    "            param_grid=param_grid,  \\\n",
    "            n_jobs=-1,  \\\n",
    "            cv=10, \\\n",
    "            scoring=scoring, \\\n",
    "            verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['stop_lat', 'stop_lon']]\n",
    "X = df.drop(['stop_lat', 'stop_lon'], axis=1)\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "gs.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   20.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=99, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1, X2, y1, y2 = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "reg = RandomForestRegressor(n_jobs=-1, random_state=99, verbose=2)\n",
    "reg.fit(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "preds = reg.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41.1828552 , 41.164437  , 41.1575046 , ..., 41.1635664 ,\n",
       "       41.21931485, 41.16710235])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stop_lat  stop_lon\n",
      "186295  41.147118 -8.607591\n",
      "127847  41.140926 -8.615259\n",
      "274740  41.180877 -8.654238\n",
      "74908   41.169924 -8.661240\n",
      "11630   41.159187 -8.682390\n",
      "196075  41.174523 -8.645301\n",
      "73229   41.148054 -8.599050\n",
      "254953  41.129937 -8.594577\n",
      "84602   41.174532 -8.567487\n",
      "210884  41.148990 -8.610651\n",
      "278828  41.162238 -8.613450\n",
      "148628  41.147271 -8.620371\n",
      "224342  41.195610 -8.703765\n",
      "194353  41.144157 -8.605746\n",
      "203786  41.154696 -8.649693\n",
      "183881  41.190363 -8.577747\n",
      "228651  41.161725 -8.651151\n",
      "281371  41.174964 -8.688888\n",
      "12280   41.164515 -8.600553\n",
      "221003  41.147532 -8.622279\n",
      "29631   41.148144 -8.614989\n",
      "203181  41.176341 -8.585649\n",
      "292660  41.237577 -8.670303\n",
      "231986  41.117328 -8.645409\n",
      "17499   41.175414 -8.613882\n",
      "131146  41.137317 -8.615493\n",
      "87444   41.180913 -8.582661\n",
      "206704  41.163165 -8.623161\n",
      "229838  41.180976 -8.624979\n",
      "7155    41.147100 -8.606871\n",
      "...           ...       ...\n",
      "123855  41.160078 -8.640954\n",
      "2747    41.174064 -8.545923\n",
      "130523  41.145732 -8.607348\n",
      "149503  41.151474 -8.600202\n",
      "156730  41.142771 -8.552754\n",
      "258795  41.177736 -8.624421\n",
      "184779  41.160834 -8.629596\n",
      "214176  41.141322 -8.613837\n",
      "235796  41.145309 -8.627265\n",
      "103355  41.181021 -8.654310\n",
      "267455  41.216841 -8.294670\n",
      "199041  41.152239 -8.662905\n",
      "252709  41.153292 -8.670807\n",
      "194027  41.144850 -8.606691\n",
      "262913  41.193216 -8.619039\n",
      "64820   41.126220 -8.623125\n",
      "41090   41.179482 -8.589249\n",
      "278167  41.160177 -8.578674\n",
      "191335  41.133501 -8.612946\n",
      "175203  41.172048 -8.626266\n",
      "87498   41.139009 -8.630172\n",
      "137337  41.147199 -8.622450\n",
      "54886   41.148108 -8.624250\n",
      "207892  41.157576 -8.622486\n",
      "110268  41.149080 -8.620821\n",
      "119879  41.245767 -8.595504\n",
      "259178  41.157567 -8.627256\n",
      "131932  41.159034 -8.608329\n",
      "146867  41.152221 -8.646804\n",
      "121958  41.161320 -8.571069\n",
      "\n",
      "[210000 rows x 2 columns] [[41.147046   -8.6052519 ]\n",
      " [41.14389082 -8.62301655]\n",
      " [41.17069337 -8.64242203]\n",
      " ...\n",
      " [41.1553629  -8.6078142 ]\n",
      " [41.1576315  -8.64318078]\n",
      " [41.16528    -8.582823  ]]\n",
      "y_real:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "-----\n",
      "y_pred:\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a46396\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\a46396\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.9639253228300669"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring(reg, X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41.147118, -8.607591],\n",
       "       [41.140926, -8.615259],\n",
       "       [41.180877, -8.654238],\n",
       "       ...,\n",
       "       [41.159034, -8.608329],\n",
       "       [41.152221, -8.646804],\n",
       "       [41.16132 , -8.571069]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
